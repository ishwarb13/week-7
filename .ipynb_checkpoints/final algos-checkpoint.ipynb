{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming with Python MOD007891 \n",
    "## Assessment Element 010 ( Weighting = 100% )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1:  ( Analysis of Diabetic Patient Data ) - ( Weighting = 30% )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is originally from the **National Institute of Diabetes and Digestive and Kidney Diseases.** The dataset consist of several medical predictor **(independent)** variables and one target **(dependent)** variable, Outcome. \n",
    "\n",
    "Independent variables include:\n",
    "\n",
    "- Number of times pregnant.\n",
    "- Plasma glucose concentration a 2 hours in an oral glucose tolerance test.\n",
    "- Diastolic blood pressure (mm Hg).\n",
    "- Triceps skinfold thickness (mm).\n",
    "- Two-Hour serum insulin (mu U/ml).\n",
    "- Body mass index (weight in kg/(height in m)^2).\n",
    "- Diabetes pedigree function.\n",
    "- Age (years).\n",
    "- Outcome: Class variable (0 or 1).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload the provided dataset (diabetes.csv) into your Jupyter Notebook working directory and then complete the following tasks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'diabetes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m      5\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdiabetes.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'diabetes.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "df = pd.read_csv(\"diabetes.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Identify the total number of records? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will give the total elements in the dataframe\n",
    "df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Display data types for all columns? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will give the Data type of every column in the Data frame.\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Check the dataset for the missing values? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The .isnull() function will check for missing values in the data frame and will give boolean output.\n",
    "#The .sum() function will give the sum of all the True values given by the .isnull function. \n",
    "df.isnull().sum()\n",
    "# (df == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Display descriptive statistics include those that summarize the central tendency, dispersion and shape of a dataset such as total count, min, max, standard deviation, max and quartiles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you probably have noticed, many columns have a **minimum value of 0** which is clearly not logical. Those are essentially **missing values** in our dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Identify columns with missing values and find out their frequency? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Identify the number of positive and negative patients based on target (dependent) variable, outcome? Plot the frequencies using a bar chart?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here .values_counts() function gives the total number of positive and negative patients.\n",
    "# first bar represents the number of positive patients (ie.1) and Second bar represents the number of negative patients(ie.0)\n",
    "\n",
    "df['Outcome'].value_counts(sort=False).plot.bar()\n",
    "df['Outcome'].value_counts(sort=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Display correlation among all dependent and independent variables using the correlation matrix? Illustrate correlation data using a heatmap plot?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# pear_corr = a.corr(method='pearson')\n",
    "# fig, ax = plt.subplots(figsize=(8,8))\n",
    "# im = ax.imshow(pear_corr, interpolation='nearest')\n",
    "# #fig.colorbar(im, orientation='vertical', fraction = 0.05)\n",
    "# fig.colorbar(im, orientation='vertical', fraction = 0.05)\n",
    "\n",
    "# # Show all ticks and label them with the dataframe column name\n",
    "# ax.set_xticklabels(df.columns, rotation=90, fontsize=15)\n",
    "# ax.set_yticklabels(df.columns, rotation=0, fontsize=15)\n",
    "\n",
    "# # Loop over data dimensions and create text annotations\n",
    "# for i in range(len(df.columns)-1):\n",
    "#     for j in range(len(df.columns)-1):\n",
    "#         text = ax.text(j, i, round(pear_corr.to_numpy()[i, j], 2),\n",
    "#                        ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "#The .corr() function gives the correlation matric for the specified data frame.\n",
    "sns.heatmap(df.corr(),annot=True,fmt='.1f',cmap='gist_ncar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have observed earlier that missing values in this dataset are represented by 0. This is clearly not a good practice and negatively impacts our data analysis. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Replace these zero values with NAN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (df.drop('Outcome', 1).replace(0, np.nan))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['Outcome'] = df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Check out the variables for 0 value once again?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a == 0).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Check out the missing values counts per variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Identify the mean value for each variable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df = df.mean()\n",
    "print(mean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. For the following columns, fill missing values with mean column values?  \n",
    "- Glucose\n",
    "- BloodPressure\n",
    "- SkinThickness\n",
    "- Insulin\n",
    "- BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['Glucose'].fillna(a['Glucose'].mean(),inplace=True)\n",
    "a['BloodPressure'].fillna(a['BloodPressure'].mean(),inplace=True)\n",
    "a['SkinThickness'].fillna(a['SkinThickness'].mean(),inplace=True)\n",
    "a['Insulin'].fillna(a['Insulin'].mean(),inplace=True)\n",
    "a['BMI'].fillna(a['BMI'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Display descriptive statistics and checkout the min values of the aforementioned columns once again? Any ZEROS ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Check out the missing values counts per variable, once again? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Plot data distribution of each variable? Explain your thoughts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in a.columns :\n",
    "    df[col].hist()\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Boxplot is a method for graphically depicting groups of numerical data through their quartiles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Plot the Boxplot for each variable? interpret the diagrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop willl run through all the columns of the data frame except the outcomes columns.\n",
    "for column in df.drop('Outcome',1):\n",
    "    plt.figure()\n",
    "    df.boxplot([column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Plot demographic and distribution of diabetics/nondiabetics across age variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take data for outcome with diabetes and no diabetes seperately\n",
    "#Plot different plots (boxplot, histogram) for both datas wrt 'Pregnancies'\n",
    "#compare\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.histplot(data=df,x='Age',bins=25,hue='Outcome',multiple='stack')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Investigate how the number of pregnancies impacts diabetes? Demonstrate the relationship with a plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Check if there are any outliers in our dataset. Any data point outside 25% and 75% quarters can be considered an outlier. Remove the outliers from our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier - less than 25 % (use qunatile function) more than 75%\n",
    "# Remove outliers and save to diff variable\n",
    "q1 = a.quantile(0.25)\n",
    "q3 = a.quantile(0.75)\n",
    "df2=a.drop('Outcome',1)\n",
    "outlier_a = df2[(df2 < q1) | (df2 > q3)].replace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20. Create a new categorical variable based on BMI using the following criteria. Name the new variable “BMI_tier” and add it to our dataset as a new column. \n",
    "\n",
    "- BMI = 0  then “NA”\n",
    "- 0 < BMI < 18.5 then “Under Weight”\n",
    "- 18.5 <= BMI < 25 then “Normal”\n",
    "- 25 <= BMI < 30 then “Overweight” \n",
    "- 30 <= BMI then “Obese”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_a['BMI_tier'] = outlier_a['BMI']\n",
    "outlier_a['BMI_tier']\n",
    "for values in outlier_a['BMI_tier']:\n",
    "    if values < na\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Plot the BMI_tier histogram ?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ages = outlier_a['Age']\n",
    "\n",
    "# bins = [-1,0,18.5,25,30,1200]\n",
    "# labels = ['NA','Under Weight', 'Normal', 'Overweight', 'Obese']\n",
    "# ages['agerange'] = pd.cut(ages, bins, labels = labels,include_lowest = True)\n",
    "\n",
    "\n",
    "# print(ages['agerange'][:52])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. How many obese individuals exist in our dataset?  Use  Piechart to illustrate the proportion of each BMI tier? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_a.head(-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. Create a new categorical variable based on Oral Glucose Tolerance Test (Glucose) using the following criteria, suggested by DIABETES UK. Name the new variable “OGTT_tier” and add it to our dataset as a new column. \n",
    "\n",
    "- Glucose == 0 then “NA”\n",
    "- Glucose < 140 then “Normal”\n",
    "- 140 <= Glucose < 198 then “Impaired Glucose Tolerance”\n",
    "- 198 <= Glucose then “Diabetic Level”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = outlier_a['Glucose']\n",
    "\n",
    "bins = [-1,0,139,197,1000]\n",
    "labels = [ 'NA','Normal', 'Impaired Glucose Tolerance','Diabetic level']\n",
    "ages['agerange'] = pd.cut(ages, bins, labels = labels,include_lowest = True)\n",
    "\n",
    "\n",
    "print(ages['agerange'][:76])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24.How many individuals are categorized as “Diabetic Level” in our newly created variable, “OGTT_tier”?  Plot the “OGTT_tier” histogram?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25. Out of those who categorized as “Impaired Glucose Tolerance”, how many of them are actually diabetes? What about those with “Normal” OGTT_tier?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2:  ( 2021  Tokyo Olympics ) - ( Weighting = 30% )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task we work with 2021 Tokyo summer Olympics dataset. This contains the details of over 11,000 athletes, with 47 disciplines, along with 743 Teams taking part in the 2021(2020) Tokyo Olympics. This dataset contains the details of the Athletes, Coaches, Teams participating as well as the Entries by gender. It contains their names, countries represented, discipline, gender of competitors, name of the coaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "athlete_data = pd.read_excel(\"Athletes.xlsx\")\n",
    "coach_data = pd.read_excel(\"Coaches.xlsx\")\n",
    "gender_data = pd.read_excel(\"EntriesGender.xlsx\")\n",
    "medal_data = pd.read_excel(\"Medals.xlsx\")\n",
    "team_data = pd.read_excel(\"Teams.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the first few rows for each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "athlete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coach_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noc_count = athlete_data['Discipline'].value_counts().reset_index()\n",
    "noc_count.columns = ['Discipline', 'athlete_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "athlete_data.merge(gender_data,on ='Discipline', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medal_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "athlete_data['Discipline'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Which countries do most athletes come from? Plot a descendingly ordered bar plot to show athletes counts based on their country of origin? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "athlete_data['NOC'].value_counts().index[0]\n",
    "# United States Of America - 615 athletes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions and methods - method() or .method()\n",
    "# atributes are without paranthesis,,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As all countries are not visible, plotting top 25 countries\n",
    "plot_1 = athlete_data['NOC'].value_counts(ascending = False).iloc[:25]\n",
    "plot_1\n",
    "plot_1.plot(kind='bar', legend=None, figsize=(20, 10))\n",
    "ticks = plt.xticks(fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Which country has the most female athletes? Plot a descendingly ordered bar plot to show female athletes counts based on their country of origin?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_data.merge(athlete_data, how = 'inner', on = 'Discipline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender_data.sort_values('Female', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Which country has the least female athletes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Which sport is most popular (based on athletes counts)  and which country has the highest participants in it? Plot a descendingly ordered bar plot to show athlete counts in different sports? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "athlete_data['Discipline'].value_counts().max\n",
    "#Athletics is the most popular sport with 2068 athletes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Plot a descendingly ordered categorical bar plot to show gender segregated athlete counts in different sports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_data.index\n",
    "sort_gender = gender_data.sort_values('Total')\n",
    "plt.bar(sort_gender.index.values, height=sort_gender['Female'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_data.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Which sport has they highest proportion of male to female athletes? Plot a descendingly ordered bar plot to depict male to female athletes proportion across different sports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Which country recieved most gold medals? Which recieved most silver and most bronze? Which received least for each? Use bar plot to for illustration.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Which country has the highest number of medals (Gold – Silver- Bronze) per capita (participants)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. List countries with no medals? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medal_data.head(2)\n",
    "medal_data.value_counts(sort = True)\n",
    "Total_1 =(medal_data['Total']==0).value_counts()\n",
    "Total_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Which country had the greatest number of coaches. Plot a descendingly ordered bar plot to show coach counts in different countries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Plot a descendingly ordered bar plot to show coach counts across different sports.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Identify the most popular coach, female and male athlete first name? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4:  ( Show Analysis ) - ( Weighting = 20% )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on the provided show dataset, please answer the following questions: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import the dataset in to your workspace as a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data = pd.read_csv(\"C:/Users/kship/OneDrive/Documents/Ishwar/Assessment Question/show.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Removed all duplicates and perform normal cleaning procedure if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data.duplicated(subset = 'title').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.drop_duplicates(subset=['title'])\n",
    "temp['title'] = pd.Series(show_data['title'], dtype=\"string\")\n",
    "\n",
    "temp.info()\n",
    "temp.drop_duplicates(subset='title')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Changing datatype of date_added column to datetime so you can conduct time based analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create 3 separate columns for week-day, month, and year based on the date_added column and name them month_added,\tyear_added, and\tday_added respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data['date_added'] = pd.to_datetime(show_data['date_added'])\n",
    "\n",
    "show_data['day_added'] = show_data['date_added'].dt.day_name()\n",
    "show_data['month_added'] = pd.DatetimeIndex(show_data['date_added']).month\n",
    "show_data['year_added']=pd.DatetimeIndex(show_data['date_added']).year\n",
    "show_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Group shows by their type and display the frequency of each type. Also, use a piechart to display show type percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topcontent_countries = show_data.groupby('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Display the number of shows that each director has ever directed along with the show type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Display the top 10 most active directors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data['director'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Group shows based on country and type. Display their frequency too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "shows_country_type =  show_data.groupby(['country','type'])\n",
    "shows_country_type=shows_country_type.size().unstack()\n",
    "shows_country_type.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "topcontent_countries = show_data.groupby('country').count().sort_values('type',ascending=False)\n",
    "\n",
    "topcontent_countries.reset_index(inplace=True)\n",
    "\n",
    "topcontent_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 15))\n",
    "\n",
    "sns.barplot(topcontent_countries.type,topcontent_countries.country.head(20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shows_country_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Identify countries with the highest number of show production (top 10). Display their show production frequency too. Beside table, use bar plot to articulate your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shows_country_type =  show_data.groupby(['country']).count()[show_id] \n",
    "sort values\n",
    "shows_country_type=shows_country_type.size().unstack()\n",
    "shows_country_type.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Group shows based on the listed_in (genre) feature. Display their frequency too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Identify the top 10 most popular genre based on the listed_in feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Use line plot to display show frequency per year segregated by show type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#year and type grpby , count with show_id\n",
    "topcontent_countries = show_data.groupby('year').count().sort_values('type')\n",
    "topcontent_countries.reset_index(inplace=True)\n",
    "topcontent_countries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 15))\n",
    "sns.lineplot(topcontent_countries.year,topcontent_countries.type);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3:  ( Chessboard ) - ( Weighting = 10% )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A chessboard is an eight-by-eight grid of squares. A queen is a chess piece that can\n",
    "move on the chessboard any number of squares along any row, column, or diagonal.\n",
    "A queen is attacking another piece if in a single move, it can move to the square the\n",
    "piece is on without jumping over any other piece. (In other words, if the other piece is\n",
    "in the line of sight of the queen, then it is attacked by it.) The eight queens problem\n",
    "poses the question of how eight queens can be placed on a chessboard without any\n",
    "queen attacking another queen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![queens](queen.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To represent squares on the chessboard, we will assign each an integer row and an\n",
    "integer column. We can ensure each of the eight queens is not on the same column\n",
    "by simply assigning them sequentially the columns 1 through 8. The variables in our\n",
    "constraint-satisfaction problem can just be the column of the queen in question. The\n",
    "domains can be the possible rows (again, 1 through 8)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a piece of code that prints out all the possible arrangements of eight queens on the chessboard. \n",
    "**Important:** Your code must be fully commented. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 1, 0, 0]\n",
      "[0, 0, 1, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 1, 0]\n",
      "[0, 1, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "N = 8\n",
    "\n",
    "# First we need to create a chessboard grid.\n",
    "# eight-by-eight matrix with all elements intially set to 0.\n",
    "\n",
    "chessboard = [[0]*N for k in range(N)]\n",
    "\n",
    "#Here we check if the new queen to be placed can be attacked vertically or horizontally by the queens placed earlier\n",
    "def safe(i, j):\n",
    "    for a in range(0,N):\n",
    "        if chessboard[i][a] == 1 or chessboard[a][j] == 1:\n",
    "            return True\n",
    "    #In this loop we check if all the diagonal spaces are safe for us to place the queen.\n",
    "    for a in range(0,N):\n",
    "        for b in range(0,N):\n",
    "            if (a+b == i+j) or (a-b == i-j):\n",
    "                if chessboard[a][b] == 1:\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "# now we need to place the queens on appropiate positions.\n",
    "# we define a function to check with above piece of code and place the queens if all the conditions the met.\n",
    "\n",
    "def Place_queens(n):\n",
    "    if n==0:\n",
    "        return True\n",
    "    for i in range(0,N):\n",
    "        for j in range(0,N):\n",
    "            # This, if condition will check with the safe function and will put 1 in safe position for the queen.\n",
    "            if (not(safe(i,j))) and (chessboard[i][j]!=1):\n",
    "                chessboard[i][j] = 1\n",
    "                # Here all the the positions that might be attacked by other queens will be set to 0.\n",
    "                if Place_queens(n-1)==True:\n",
    "                    return True\n",
    "                chessboard[i][j] = 0\n",
    "    return False\n",
    "Place_queens(N)\n",
    "# To represent the matrix in the form of a chessboard we run a for loop.\n",
    "for i in chessboard:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4:  ( Encryption ) - ( Weighting = 10% )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encryption is the method by which information is converted into secret code that hides the information's true meaning. The science of encrypting and decrypting information is called cryptography.\n",
    "\n",
    "In computing, unencrypted data is also known as plaintext, and encrypted data is called ciphertext. The formulas used to encode and decode messages are called encryption algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you need to create a simple transposition encryption algorithms where plaintext characters are re-arranged instead of replaced to encode a message. This algorithm  encodes a message by writing it down and up diagonally over successive rows as illustrated below. For example, the secret message **“THIS IS A SECRET MESSAGE”** encoded over 4 rails would look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![queens](cipher.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create the ciphertext by reading off characters left to right, top to bottom. For our example message, the cipher text becomes:\n",
    "\n",
    "**TATGHSSEMAEIIERESSCS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a piece of code capable of **encrypting** and **decrypting** a message using the aforementioned technique.  Use the last digit (most right) of your **SID** as the encryption key. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample input plainText: **You speak an infinite deal of nothing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tatghssemaeiieresscs\n"
     ]
    }
   ],
   "source": [
    "#PART 1\n",
    "\n",
    "# Encription code for a text with 4 rail ?\n",
    "# Input text is 'THIS IS A SECRET MESSAGE'.\n",
    "# Expected Output  TATGHSSEMAEIIERESSCS.\n",
    "\n",
    "# we need to create an array.\n",
    "# first let's define a function to encrypt an given text.\n",
    "\n",
    "def Encription_algo(msg,key):\n",
    "    # This command will remove all the spaces in the given sentence and will pass a single word to the function.\n",
    "    # Which will help us get the desired results.\n",
    "    Message=msg.replace(\" \",\"\")\n",
    "    rails = [['\\n' for i in range(len(Message))]\n",
    "                  for j in range(key)]\n",
    "    \n",
    "    for i  in range(len(Message)):\n",
    "        for j in range(key):\n",
    "            row,col = 0,0\n",
    "        flag = False     \n",
    "\n",
    "    for i in range(len(Message)):\n",
    "        if (row==0) or (row==key-1):\n",
    "            flag = not flag\n",
    "        rails[row][col]=Message[i]\n",
    "        col+=1\n",
    "        if flag:\n",
    "            row=row+1\n",
    "        else:\n",
    "            row-=1\n",
    "\n",
    "        Final = []\n",
    "        for i in range (key):\n",
    "            for j in range(len(Message)):\n",
    "                if rails[i][j] !='\\n':\n",
    "                    Final.append(rails[i][j])\n",
    "    return(\"\".join(Final))\n",
    "print(Encription_algo(\"This is a secret message\",4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ye tliopaninea hnuskani entg  fdo\n",
      "You speak an infinte deal nothing\n"
     ]
    }
   ],
   "source": [
    "#PART 2\n",
    "\n",
    "#Encripting and Decripting an given text/sentence?\n",
    "#Input text is \"You speak a infinite deal of nothing\"\n",
    "\n",
    "def Encription_algo(message,key):\n",
    "    \n",
    "    rail = [['\\n' for i in range(len(message))]\n",
    "                  for j in range(key)]\n",
    "    \n",
    "    for i  in range(len(message)):\n",
    "        for j in range(key):\n",
    "            row,col = 0,0\n",
    "        flag = False     \n",
    "\n",
    "    for i in range(len(message)):\n",
    "        if (row==0) or (row==key-1):\n",
    "            flag = not flag\n",
    "        rail[row][col]=message[i]\n",
    "        col+=1\n",
    "        if flag:\n",
    "            row=row+1\n",
    "        else:\n",
    "            row-=1\n",
    "\n",
    "        Final = []\n",
    "        for i in range (key):\n",
    "            for j in range(len(message)):\n",
    "                if rail[i][j] !='\\n':\n",
    "                    Final.append(rail[i][j])\n",
    "    return(\"\".join(Final))\n",
    "result = (print(Encription_algo(\"You speak an infinte deal nothing\",4)))\n",
    "\n",
    "# Now that we have encripted the given text.\n",
    "#let's create another function for Decription.\n",
    "#Here the Input will be the output of above code. \n",
    "#ie. the encripted part of the given text.\n",
    "\n",
    "def Decription_algo(message, key):\n",
    " \n",
    "    # create the matrix to cipher\n",
    "    # plain text key = rows ,\n",
    "    # length(text) = columns\n",
    "    # filling the rail matrix to\n",
    "    # distinguish filled spaces\n",
    "    # from blank ones\n",
    "    rails = [['\\n' for i in range(len(message))]\n",
    "                  for j in range(key)]\n",
    "     \n",
    "    # to find the direction\n",
    "    Flag = None\n",
    "    row, col = 0, 0\n",
    "     \n",
    "    # mark the places with '$'\n",
    "    for i in range(len(message)):\n",
    "        if row == 0:\n",
    "            Flag = True\n",
    "        if row == key - 1:\n",
    "            Flag = False\n",
    "         \n",
    "        # place the marker\n",
    "        rails[row][col] = '$'\n",
    "        col += 1\n",
    "         \n",
    "        # find the next row\n",
    "        # using direction flag\n",
    "        if Flag:\n",
    "            row += 1\n",
    "        else:\n",
    "            row -= 1\n",
    "             \n",
    "    # now we can construct the\n",
    "    # fill the rail matrix\n",
    "    index = 0\n",
    "    for i in range(key):\n",
    "        for j in range(len(message)):\n",
    "            if ((rails[i][j] == '$') and\n",
    "               (index < len(message))):\n",
    "                rails[i][j] = message[index]\n",
    "                index += 1\n",
    "         \n",
    "    # now read the matrix in\n",
    "    # zig-zag manner to construct\n",
    "    # the resultant text\n",
    "    Final = []\n",
    "    row, col = 0, 0\n",
    "    for i in range(len(message)):\n",
    "         \n",
    "        # check the direction of flow\n",
    "        if row == 0:\n",
    "            Flag = True\n",
    "        if row == key-1:\n",
    "            Flag = False\n",
    "             \n",
    "        # place the marker\n",
    "        if (rails[row][col] != '$'):\n",
    "            Final.append(rails[row][col])\n",
    "            col += 1\n",
    "             \n",
    "        # find the next row using\n",
    "        # direction flag\n",
    "        if Flag:\n",
    "            row += 1\n",
    "        else:\n",
    "            row -= 1\n",
    "    return(\"\".join(Final))\n",
    "print(Decription_algo(\"Ye tliopaninea hnuskani entg  fdo\", 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good Luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
